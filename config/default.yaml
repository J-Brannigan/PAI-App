# App model settings
model:
  provider: openai
  name: gpt-5-nano-2025-08-07

providers:
  openai:
    params: { temperature: 0.2 }
    timeout: 60
    strict_params: false
    debug_params: true
  echo:
    token_delay: 0.08

secrets:
  method: env
  mapping:
    openai: {api_key: OPENAI_API_KEY}

# Transcript storage
storage:
  backend: file
  transcripts_dir: sessions
  resume: null

# Runtime behaviour
runtime:
  stream: true

# UI
ui:
  config: ui.yaml

# Token context
context:
  max_input_tokens: 6000          # hard cap for request messages
  response_reserve_tokens: 1000   # leave room for the model's reply
  always_keep_last_n: 6           # keep the last N messages (plus the system prompt)